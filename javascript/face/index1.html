<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>顔認識</title>
<style>
  /* video 要素の上に canvas 要素をオーバーレイするための CSS */
  #container {              /* コンテナ用の div について */
    position: relative;     /* 座標指定を相対値指定にする */
  }
  #video {                  /* カメラ映像を流す video について */
    transform: scaleX(-1);  /* 左右反転させる */
  }
  #canvas {                 /* 描画用の canvas について */
    transform: scaleX(-1);  /* 左右反転させる */
    position: absolute;     /* 座標指定を絶対値指定にして */
    left: 0;                /* X座標を0に */
    top: 0;                 /* Y座標を0に */
  }
</style>
</head>

<body>
<div id="container">  <!-- video の上に canvas をオーバーレイするための div 要素 -->
  <video id="video" width="400" height="300" autoplay></video>  <!-- カメラ映像を流す video -->
  <canvas id="canvas" width="400" height="300"></canvas>        <!-- 重ねて描画する canvas -->
</div>
<div id="dat"></div>  <!-- データ表示用 div 要素 -->

<!-- clmtrackr 関連ファイルの読み込み -->
<script src="clmtrackr.js"></script>          <!-- clmtrackr のメインライブラリの読み込み -->
<script src="model_pca_20_svm.js"></script>   <!-- 顔モデル（※）の読み込み -->

<script>
// もろもろの準備
var video = document.getElementById("video");           // video 要素を取得
var canvas = document.getElementById("canvas");         // canvas 要素の取得
var context = canvas.getContext("2d");                  // canvas の context の取得

// getUserMedia によるカメラ映像の取得
var media = navigator.mediaDevices.getUserMedia({       // メディアデバイスを取得
  video: {facingMode: "user"},                          // カメラの映像を使う（スマホならインカメラ）
  audio: false                                          // マイクの音声は使わない
});
media.then((stream) => {                                // メディアデバイスが取得できたら
  video.src = window.URL.createObjectURL(stream);       // video 要素にストリームを渡す
});

// clmtrackr の開始
var tracker = new clm.tracker();  // tracker オブジェクトを作成
tracker.init(pModel);             // tracker を所定のフェイスモデル（※）で初期化
tracker.start(video);             // video 要素内でフェイストラッキング開始

// 描画ループ
function drawLoop() {
  requestAnimationFrame(drawLoop);                      // drawLoop 関数を繰り返し実行
  var positions = tracker.getCurrentPosition();         // 顔部品の現在位置の取得
  showData(positions);                                  // データの表示
  context.clearRect(0, 0, canvas.width, canvas.height); // canvas をクリア
  tracker.draw(canvas);                                 // canvas にトラッキング結果を描画
}
drawLoop();                                             // drawLoop 関数をトリガー

// 顔部品（特徴点）の位置データを表示する showData 関数
function showData(pos) {
  var str = "";                                         // データの文字列を入れる変数
  for(var i = 0; i < pos.length; i++) {                 // 全ての特徴点（71個）について
    str += "特徴点" + i + ": ("
         + Math.round(pos[i][0]) + ", "                 // X座標（四捨五入して整数に）
         + Math.round(pos[i][1]) + ")<br>";             // Y座標（四捨五入して整数に）
  }
  var dat = document.getElementById("dat");             // データ表示用div要素の取得
  dat.innerHTML = str;                                  // データ文字列の表示
}
</script>
</body>
</html>